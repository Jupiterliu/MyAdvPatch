{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "adversarial_examples.ipynb",
   "version": "0.3.2",
   "provenance": [],
   "collapsed_sections": [
    "cUGQIN7TDugJ"
   ],
   "toc_visible": true
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "metadata": {
    "id": "pQJVwnBwWFQp",
    "colab_type": "text"
   },
   "cell_type": "markdown",
   "source": [
    "# Run my code\n"
   ]
  },
  {
   "metadata": {
    "id": "mAhpOAfODY68",
    "colab_type": "text"
   },
   "cell_type": "markdown",
   "source": [
    "Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'load_data'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-2-3a4208897d73>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0;32mfrom\u001B[0m \u001B[0mload_data\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0;34m*\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      2\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mPIL\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mload_data\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mgc\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mmatplotlib\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpyplot\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0mplt\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mModuleNotFoundError\u001B[0m: No module named 'load_data'"
     ]
    }
   ],
   "source": [
    "from load_data import *\n",
    "import PIL\n",
    "import load_data\n",
    "import gc\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import autograd\n",
    "plt.rcParams[\"axes.grid\"] = False\n",
    "plt.axis('off')\n",
    "\n",
    "img_dir = \"person\"  # \"inria/Train/pos\"\n",
    "lab_dir = \"person/yolo-labels\"  # \"inria/Train/pos/yolo-labels\"\n",
    "cfgfile = \"cfg/yolo.cfg\"\n",
    "weightfile = \"weights/yolo.weights\"\n",
    "printfile = \"non_printability/30values.txt\"\n",
    "patch_size = 300\n",
    "\n",
    "print('LOADING MODELS')\n",
    "darknet_model = Darknet(cfgfile)\n",
    "darknet_model.load_weights(weightfile)\n",
    "darknet_model = darknet_model.eval().cuda()\n",
    "patch_applier = PatchApplier().cuda()\n",
    "patch_transformer = PatchTransformer().cuda()\n",
    "prob_extractor = MaxProbExtractor(0, 80).cuda()\n",
    "nps_calculator = NPSCalculator(printfile, patch_size)\n",
    "nps_calculator = nps_calculator.cuda()\n",
    "total_variation = TotalVariation().cuda()\n",
    "print('MODELS LOADED')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "img_size = darknet_model.height\n",
    "batch_size = 6#10#18\n",
    "n_epochs = 10000\n",
    "max_lab = 14\n",
    "\n",
    "# Choose between initializing with gray or random\n",
    "adv_patch_cpu = torch.full((3,patch_size,patch_size),0.5)\n",
    "#adv_patch_cpu = torch.rand((3,patch_size,patch_size))\n",
    "\n",
    "\n",
    "patch_img = Image.open(\"saved_patches/patchnew0.jpg\").convert('RGB')\n",
    "tf = transforms.Resize((patch_size,patch_size))\n",
    "patch_img = tf(patch_img)\n",
    "tf = transforms.ToTensor()\n",
    "adv_patch_cpu = tf(patch_img)\n",
    "\n",
    "adv_patch_cpu.requires_grad_(True)\n",
    "\n",
    "\n",
    "print('INITIALIZING DATALOADER')\n",
    "train_loader = torch.utils.data.DataLoader(InriaDataset(img_dir, lab_dir, max_lab, img_size, shuffle=True),\n",
    "                                              batch_size=batch_size,\n",
    "                                              shuffle=True,\n",
    "                                              num_workers=10)\n",
    "print('DATALOADER INITIALIZED')\n",
    "\n",
    "optimizer = optim.Adam([adv_patch_cpu], lr=.03, amsgrad=True)\n",
    "\n",
    "#try:\n",
    "et0 = time.time()\n",
    "for epoch in range(n_epochs):\n",
    "    ep_det_loss = 0\n",
    "    bt0 = time.time()\n",
    "    for i_batch, (img_batch, lab_batch) in enumerate(train_loader):\n",
    "        with autograd.detect_anomaly():\n",
    "            img_batch = img_batch.cuda()\n",
    "            lab_batch = lab_batch.cuda()\n",
    "            #print('TRAINING EPOCH %i, BATCH %i'%(epoch, i_batch))\n",
    "            adv_patch = adv_patch_cpu.cuda()\n",
    "            adv_batch_t = patch_transformer(adv_patch, lab_batch, img_size, do_rotate=True)\n",
    "            p_img_batch = patch_applier(img_batch, adv_batch_t)\n",
    "            p_img_batch = F.interpolate(p_img_batch,(darknet_model.height, darknet_model.width))\n",
    "            output = darknet_model(p_img_batch)\n",
    "            max_prob = prob_extractor(output)\n",
    "            nps = nps_calculator(adv_patch)\n",
    "            tv = total_variation(adv_patch)\n",
    "\n",
    "            det_loss = torch.mean(max_prob)\n",
    "            ep_det_loss += det_loss.detach().cpu().numpy()\n",
    "            '''\n",
    "            nps_loss = nps\n",
    "            tv_loss = tv*8\n",
    "            loss = nps_loss + (det_loss**3/tv_loss + tv_loss**3/det_loss)**(1/3)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            adv_patch_cpu.data.clamp_(0,1)       #keep patch in image range\n",
    "\n",
    "            '''\n",
    "            nps_loss = nps*0.01\n",
    "            tv_loss = tv*2.5\n",
    "            loss = det_loss + nps_loss + tv_loss\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            adv_patch_cpu.data.clamp_(0,1)       #keep patch in image range\n",
    "\n",
    "            bt1 = time.time()\n",
    "            if i_batch%5 == 0:\n",
    "                print('BATCH', i_batch, end='...\\n')\n",
    "                im = transforms.ToPILImage('RGB')(adv_patch_cpu)\n",
    "                plt.imshow(im)\n",
    "                plt.show()\n",
    "            '''\n",
    "            print('  BATCH NR: ', i_batch)\n",
    "            print('BATCH LOSS: ', loss.detach().cpu().numpy())\n",
    "            print('  DET LOSS: ', det_loss.detach().cpu().numpy())\n",
    "            print('  NPS LOSS: ', nps_loss.detach().cpu().numpy())\n",
    "            print('   TV LOSS: ', tv_loss.detach().cpu().numpy())\n",
    "            print('BATCH TIME: ', bt1-bt0)\n",
    "            '''\n",
    "            if i_batch + 1 >= len(train_loader):\n",
    "                print('\\n')\n",
    "            else:\n",
    "                del adv_batch_t, output, max_prob, det_loss, p_img_batch, nps_loss, tv_loss, loss\n",
    "                torch.cuda.empty_cache()\n",
    "            bt0 = time.time()\n",
    "    et1 = time.time()\n",
    "    ep_det_loss = ep_det_loss/len(train_loader)\n",
    "    ep_nps_loss = nps_loss.detach().cpu().numpy()\n",
    "    ep_tv_loss = tv_loss.detach().cpu().numpy()\n",
    "    tot_ep_loss = ep_det_loss + ep_nps_loss + ep_tv_loss\n",
    "    if True:\n",
    "        print('  EPOCH NR: ', epoch),\n",
    "        print('EPOCH LOSS: ', tot_ep_loss)\n",
    "        print('  DET LOSS: ', ep_det_loss)\n",
    "        print('  NPS LOSS: ', ep_nps_loss)\n",
    "        print('   TV LOSS: ', ep_tv_loss)\n",
    "        print('EPOCH TIME: ', et1-et0)\n",
    "        im = transforms.ToPILImage('RGB')(adv_patch_cpu)\n",
    "        plt.imshow(im)\n",
    "        plt.show()\n",
    "        im.save(\"saved_patches/patchnew1.jpg\")\n",
    "        del adv_batch_t, output, max_prob, det_loss, p_img_batch, nps_loss, tv_loss, loss\n",
    "        torch.cuda.empty_cache()\n",
    "    et0 = time.time()\n",
    "\n",
    "#except RuntimeError:\n",
    "#    torch.cuda.empty_cache()\n",
    "#    print('cuda refreshed')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "metadata": {
    "id": "cUGQIN7TDugJ",
    "colab_type": "text"
   },
   "cell_type": "markdown",
   "source": [
    "# Run my code (obsolete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "img_size = darknet_model.height\n",
    "batch_size = 6#10#18\n",
    "n_epochs = 10000\n",
    "max_lab = 14\n",
    "\n",
    "# Choose between initializing with gray or random\n",
    "adv_patch_cpu = torch.full((3,patch_size,patch_size),0.5)\n",
    "#adv_patch_cpu = torch.rand((3,patch_size,patch_size))\n",
    "\n",
    "\n",
    "patch_img = Image.open(\"saved_patches/patchnew0.jpg\").convert('RGB')\n",
    "tf = transforms.Resize((patch_size,patch_size))\n",
    "patch_img = tf(patch_img)\n",
    "tf = transforms.ToTensor()\n",
    "adv_patch_cpu = tf(patch_img)\n",
    "\n",
    "adv_patch_cpu.requires_grad_(True)\n",
    "\n",
    "\n",
    "print('INITIALIZING DATALOADER')\n",
    "train_loader = torch.utils.data.DataLoader(InriaDataset(img_dir, lab_dir, max_lab, img_size, shuffle=True),\n",
    "                                              batch_size=batch_size,\n",
    "                                              shuffle=True,\n",
    "                                              num_workers=10)\n",
    "print('DATALOADER INITIALIZED')\n",
    "\n",
    "optimizer = optim.Adam([adv_patch_cpu], lr=.03, amsgrad=True)\n",
    "\n",
    "#try: \n",
    "et0 = time.time()\n",
    "for epoch in range(n_epochs):\n",
    "    ep_det_loss = 0\n",
    "    bt0 = time.time()\n",
    "    for i_batch, (img_batch, lab_batch) in enumerate(train_loader):\n",
    "        with autograd.detect_anomaly():\n",
    "            img_batch = img_batch.cuda()\n",
    "            lab_batch = lab_batch.cuda()\n",
    "            #print('TRAINING EPOCH %i, BATCH %i'%(epoch, i_batch))\n",
    "            adv_patch = adv_patch_cpu.cuda()\n",
    "            adv_batch_t = patch_transformer(adv_patch, lab_batch, img_size, do_rotate=True)\n",
    "            p_img_batch = patch_applier(img_batch, adv_batch_t)\n",
    "            p_img_batch = F.interpolate(p_img_batch,(darknet_model.height, darknet_model.width))\n",
    "            output = darknet_model(p_img_batch)\n",
    "            max_prob = prob_extractor(output)\n",
    "            nps = nps_calculator(adv_patch)\n",
    "            tv = total_variation(adv_patch)\n",
    "\n",
    "            det_loss = torch.mean(max_prob)\n",
    "            ep_det_loss += det_loss.detach().cpu().numpy()\n",
    "            '''\n",
    "            nps_loss = nps\n",
    "            tv_loss = tv*8\n",
    "            loss = nps_loss + (det_loss**3/tv_loss + tv_loss**3/det_loss)**(1/3)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            adv_patch_cpu.data.clamp_(0,1)       #keep patch in image range\n",
    "\n",
    "            '''\n",
    "            nps_loss = nps*0.01\n",
    "            tv_loss = tv*2.5\n",
    "            loss = det_loss + nps_loss + tv_loss\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            adv_patch_cpu.data.clamp_(0,1)       #keep patch in image range\n",
    "            \n",
    "            bt1 = time.time()\n",
    "            if i_batch%5 == 0:\n",
    "                print('BATCH', i_batch, end='...\\n')\n",
    "                im = transforms.ToPILImage('RGB')(adv_patch_cpu)\n",
    "                plt.imshow(im)\n",
    "                plt.show()\n",
    "            '''\n",
    "            print('  BATCH NR: ', i_batch)\n",
    "            print('BATCH LOSS: ', loss.detach().cpu().numpy())\n",
    "            print('  DET LOSS: ', det_loss.detach().cpu().numpy())\n",
    "            print('  NPS LOSS: ', nps_loss.detach().cpu().numpy())\n",
    "            print('   TV LOSS: ', tv_loss.detach().cpu().numpy())\n",
    "            print('BATCH TIME: ', bt1-bt0)\n",
    "            '''\n",
    "            if i_batch + 1 >= len(train_loader):\n",
    "                print('\\n')\n",
    "            else:\n",
    "                del adv_batch_t, output, max_prob, det_loss, p_img_batch, nps_loss, tv_loss, loss\n",
    "                torch.cuda.empty_cache()\n",
    "            bt0 = time.time()\n",
    "    et1 = time.time()\n",
    "    ep_det_loss = ep_det_loss/len(train_loader)\n",
    "    ep_nps_loss = nps_loss.detach().cpu().numpy()\n",
    "    ep_tv_loss = tv_loss.detach().cpu().numpy()\n",
    "    tot_ep_loss = ep_det_loss + ep_nps_loss + ep_tv_loss\n",
    "    if True:\n",
    "        print('  EPOCH NR: ', epoch),\n",
    "        print('EPOCH LOSS: ', tot_ep_loss)\n",
    "        print('  DET LOSS: ', ep_det_loss)\n",
    "        print('  NPS LOSS: ', ep_nps_loss)\n",
    "        print('   TV LOSS: ', ep_tv_loss)\n",
    "        print('EPOCH TIME: ', et1-et0)\n",
    "        im = transforms.ToPILImage('RGB')(adv_patch_cpu)\n",
    "        plt.imshow(im)\n",
    "        plt.show()\n",
    "        im.save(\"saved_patches/patchnew1.jpg\")\n",
    "        del adv_batch_t, output, max_prob, det_loss, p_img_batch, nps_loss, tv_loss, loss\n",
    "        torch.cuda.empty_cache()\n",
    "    et0 = time.time()\n",
    "\n",
    "#except RuntimeError:\n",
    "#    torch.cuda.empty_cache()\n",
    "#    print('cuda refreshed')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "metadata": {
    "id": "6F3NC7IVsWMY",
    "colab_type": "text",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "cell_type": "markdown",
   "source": [
    "# Check if our patch fools the detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from utils import *\n",
    "patch_size = 300\n",
    "img_size = darknet_model.height\n",
    "\n",
    "img_dir_v = \"inria/Test/pos\"\n",
    "lab_dir_v = \"inria/Test/pos/yolo-labels\"\n",
    "\n",
    "adv_patch = Image.open(\"saved_patches/patch11.jpg\").convert('RGB')\n",
    "transform = transforms.ToTensor()\n",
    "adv_patch = transform(adv_patch).cuda()\n",
    "\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(InriaDataset(img_dir_v, lab_dir_v, 14, img_size, shuffle=True),\n",
    "                                              batch_size=1,\n",
    "                                              shuffle=True,\n",
    "                                              num_workers=10)\n",
    "\n",
    "for i_batch, (img_batch, lab_batch) in enumerate(train_loader):\n",
    "    img_size = img_batch.size(-1)\n",
    "    adv_batch_t = patch_transformer(adv_patch, lab_batch.cuda(), img_size, do_rotate=True, rand_loc=False)\n",
    "    p_img = patch_applier(img_batch.cuda(), adv_batch_t)\n",
    "    p_img = F.interpolate(p_img,(darknet_model.height, darknet_model.width))\n",
    "    output = darknet_model(p_img)\n",
    "    boxes = get_region_boxes(output,0.5,darknet_model.num_classes,\n",
    "                         darknet_model.anchors, darknet_model.num_anchors)[0]\n",
    "    boxes = nms(boxes,0.4)\n",
    "    class_names = load_class_names('data/coco.names')\n",
    "    squeezed = p_img.squeeze(0)\n",
    "    print(squeezed.shape)\n",
    "    img = transforms.ToPILImage('RGB')(squeezed.detach().cpu())\n",
    "    plotted_image = plot_boxes(img, boxes, class_names=class_names)\n",
    "    plt.imshow(plotted_image)\n",
    "    plt.show()\n",
    "'''\n",
    "# apply an image as patch\n",
    "patch_size = adv_patch.size(-1)\n",
    "horse = Image.open(\"data/horse.jpg\").convert('RGB')\n",
    "tf = transforms.Resize((patch_size,patch_size))\n",
    "horse = tf(horse)\n",
    "transform = transforms.ToTensor()\n",
    "horse = transform(horse)\n",
    "\n",
    "adv_batch_t = patch_transformer(horse.cuda(), label.cuda(), img_size)\n",
    "p_img = patch_applier(image.cuda(), adv_batch_t)\n",
    "p_img = F.interpolate(p_img,(darknet_model.height, darknet_model.width))\n",
    "output = darknet_model(p_img)\n",
    "boxes = get_region_boxes(output,0.5,darknet_model.num_classes,\n",
    "                         darknet_model.anchors, darknet_model.num_anchors)[0]\n",
    "boxes = nms(boxes,0.4)\n",
    "class_names = load_class_names('data/coco.names')\n",
    "squeezed = p_img.squeeze(0)\n",
    "im = transforms.ToPILImage('RGB')(squeezed.detach().cpu())\n",
    "plotted_image = plot_boxes(im, boxes, class_names=class_names)\n",
    "plt.imshow(plotted_image)\n",
    "plt.show()\n",
    "'''"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ]
}